{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Sequence Labeling: Part-of-Speech Tagging\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "- Understanding:\n",
    "    - Relation between Classification and Sequence Labeling\n",
    "    - Relation between Ngram Modeling and Sequence Labeling\n",
    "    - General setting for Sequence Labeling\n",
    "    - Markov Model Tagging\n",
    "    - Universal Part-of-Speech Tags\n",
    "- Learning how to:\n",
    "    - perform POS-tagging using NLTK\n",
    "    - perform POS-tagging using spacy\n",
    "    - train and test (evaluate) POS-tagger with NLTK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommended Reading\n",
    "\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Covered Material\n",
    "\n",
    "- SLP\n",
    "    - [Chapter 8: Part-of-Speech Tagging (HMMs)](https://web.stanford.edu/~jurafsky/slp3/8.pdf)\n",
    "- NLTK\n",
    "    - [Chapter 5: Part of Speech Tagging](https://www.nltk.org/book/ch05.html) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "- [spaCy](https://spacy.io/)\n",
    "- [NLTK](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Sequence Labeling (Tagging)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Sequence Labeling and Classification\n",
    "[Classification](https://en.wikipedia.org/wiki/Statistical_classification) is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.\n",
    "\n",
    "[Sequence Labeling](https://en.wikipedia.org/wiki/Sequence_labeling) is a type of pattern recognition task that involves the algorithmic assignment of a categorical label to each member of a sequence of observed values. It is a sub-class of [structured (output) learning](https://en.wikipedia.org/wiki/Structured_prediction), since we are predicting a *sequence* object rather than a discrete or real value predicted in classification problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- The problem can be treated as a set of independent classification tasks, one per member of the sequence;\n",
    "- **BUT!** performance is generally improved by making the optimal label for a given element dependent on the choices of nearby elements;\n",
    "\n",
    "Due to the complexity of the model and the interrelations of predicted variables the process of prediction using a trained model and of training itself is often computationally infeasible and [approximate inference](https://en.wikipedia.org/wiki/Approximate_inference) and learning methods are used. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.2. Sequence Labeling and Ngram Modeling\n",
    "[Markov Chain](https://en.wikipedia.org/wiki/Markov_chain) is a stochastic model used to describe sequences. It is the simplest [Markov Model](https://en.wikipedia.org/wiki/Markov_model). In order to make inference tractable, a process that generated the sequence is assumed to have [Markov Property](https://en.wikipedia.org/wiki/Markov_property), i.e. future states depend only on the current state, not on the events that occurred before it. (An [ngram](https://en.wikipedia.org/wiki/N-gram) [language model](https://en.wikipedia.org/wiki/Language_model) is a $(n-1)$-order Markov Model.) \n",
    "\n",
    "In Statical Language Modeling, we are modeling *observed sequences* represented as Markov Chains. Since the states of the process are *observable*, we only need to compute __transition probabilities__. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Sequence Labeling, we assume that *observed sequences* (__sentences__) have been generated by a Markov Process with *unobservable* (i.e. hidden) states (__labels__), i.e. [Hidden Markov Model](https://en.wikipedia.org/wiki/Hidden_Markov_model) (__HMM__). \n",
    "Since the states of the process are hidden and the output is observable, each state has a probability distribution over the possible output tokens, i.e. __emission probabilities__. \n",
    "\n",
    "Using these two probability distributions (__transition__ and __emission__), in sequence labeling, we are *inferring* the sequence of state transitions, given a sequence of observations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3. The General Setting for Sequence Labeling\n",
    "\n",
    "- Create __training__ and __testing__ sets by tagging a certain amount of text by hand\n",
    "    - i.e. map each word in corpus to a tag\n",
    "- Train tagging model to extract generalizations from the annotated __training__ set\n",
    "- Evaluate the trained tagging model on the annotated __testing__ set\n",
    "- Use the trained tagging model too annotate new texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Part-of-speech tagging (POS tagging or PoS tagging or POST), also called grammatical tagging is the process of marking up a word in a text as corresponding to a particular part of speech, based on both its definition and its context.\n",
    "\n",
    "Tag Sets vary from corpus to corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1. Universal Part of Speech Tags\n",
    "\n",
    "Universal POS-Tag Set represents a simplified and unified set of part-of-speech tags, that was proposed for the standardization across corpora and languages. \n",
    "The number of defined tags varies from 12 ([Petrov et al/Google/NLTK](https://github.com/slavpetrov/universal-pos-tags)) to 17 ([Universal Dependencies/spaCy](https://universaldependencies.org/u/pos/index.html), in *Italics*).\n",
    "\n",
    "\n",
    "\n",
    "| Tag  | Meaning | English Examples |\n",
    "|:-----|:--------|:-----------------|\n",
    "| __Open Class__ |||\n",
    "| NOUN | noun (common and proper) | year, home, costs, time, Africa\n",
    "| VERB | verb (all tenses and modes) | is, say, told, given, playing, would\n",
    "| ADJ  | adjective           | new, good, high, special, big, local\n",
    "| ADV  | adverb              | really, already, still, early, now\n",
    "| *PROPN* | proper noun (split from NOUN) | Africa\n",
    "| *INTJ*  | interjection (split from X) | oh, ouch\n",
    "| __Closed Class__ |||\n",
    "| DET  | determiner, article | the, a, some, most, every, no, which\n",
    "| PRON | pronoun             | he, their, her, its, my, I, us\n",
    "| ADP  | adposition\t(prepositions and postpositions) | on, of, at, with, by, into, under\n",
    "| NUM  | numeral             | twenty-four, fourth, 1991, 14:24\n",
    "| PRT (*PART*) | particles or other function words | at, on, out, over per, that, up, with\n",
    "| CONJ | conjunction         | and, or, but, if, while, although\n",
    "| *AUX* | auxiliary (split from VERB) | have, is, should\n",
    "| *CCONJ*  | coordinating conjunction (splits CONJ) | or, and\n",
    "| *SCONJ*  | subordinating conjunction (splits CONJ) | if, while\n",
    "| __Other__ |||\n",
    "| .    | punctuation marks   | . , ; !\n",
    "| X    | other               | foreign words, typos, abbreviations: ersatz, esprit, dunno, gr8, univeristy\n",
    "| *SYM* | symbols (split from X) | $, :) \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Part-of-Speech Tagging with Spacy & NLTK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1. Part-of-Speech Tagging with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "# nlp = spacy.load(\"en-core-web-sm\")\n",
    "\n",
    "# un-comment the lines below, if you get 'ModuleNotFoundError'\n",
    "import en_core_web_sm\n",
    "nlp = en_core_web_sm.load()\n",
    "\n",
    "\n",
    "# let's print spaCy pipeline\n",
    "print([key for key, model in nlp.pipeline])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "text = \"Oh. I have seen a man with a telescope in Antarctica.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# tokens\n",
    "print([t.text for t in doc])\n",
    "\n",
    "# Fine grained POS-tags\n",
    "print([t.tag_ for t in doc])\n",
    "\n",
    "# Coarse POS-tags (from Universal POS Tag set)\n",
    "print([t.pos_ for t in doc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. Part-of-Speech Tagging with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download('universal_tagset')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "text = \"Oh. I have seen a man with a telescope in Antarctica.\"\n",
    "\n",
    "# tokenization\n",
    "tokens = nltk.word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "# POS-tagging (with WSJ Tags)\n",
    "print(nltk.pos_tag(tokens))\n",
    "\n",
    "# POS-tagging with Universal Tags\n",
    "print(nltk.pos_tag(tokens, tagset='universal'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3. Training POS-Tagger with NLTK\n",
    "\n",
    "- Manually POS-tagged corpus\n",
    "- Sequence Labeling (Tagging) Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.1. Corpora for POS-Tagging\n",
    "NLTK provides several corpora, most of them are POS-tagged. We will use WSJ with universal tag set (automatically converted using internal mapping)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download treebank\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import treebank\n",
    "\n",
    "# WSJ POS-Tags\n",
    "print(treebank.tagged_sents()[:1])\n",
    "\n",
    "# Universal POS-Tags\n",
    "print(treebank.tagged_sents(tagset='universal')[:1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.2. NLTK Taggers\n",
    "\n",
    "NLTK provides several tagging algorithms, including \n",
    "\n",
    "- rule-based taggers\n",
    "    - Regular Expression Tagger: assigns tags to tokens by comparing their word strings to a series of regular expressions.\n",
    "\n",
    "- [Pre-Trained Taggers](http://www.nltk.org/api/nltk.tag.html)\n",
    "    - HunPoS\n",
    "    - Senna\n",
    "    - Stanford Tagger\n",
    "    \n",
    "- trainable taggers\n",
    "    - `Brill Tagger`: Brill's transformational rule-based tagger assigns an initial tag sequence to a text; and then appies an ordered list of transformational rules to correct the tags of individual tokens. Learns rules from corpus.\n",
    "    - [Greedy Averaged Perceptron](https://explosion.ai/blog/part-of-speech-pos-tagger-in-python)\n",
    "    - [TnT](http://acl.ldc.upenn.edu/A/A00/A00-1031.pdf)\n",
    "    - Hidden Markov Models\n",
    "    - Conditional Random Fields\n",
    "    - Sequential:\n",
    "        - Affix Tagger: A tagger that chooses a token's tag based on a leading or trailing substring of its word string.\n",
    "        - Ngram Tagger: A tagger that chooses a token's tag based on its word string and on the preceding _n_ word's tags.\n",
    "            - Unigram Tagger\n",
    "            - Bigram Tagger\n",
    "            - Trigram Tagger\n",
    "\n",
    "        - Classifier-based POS Tagger: A sequential tagger that uses a classifier to choose the tag for each token in a sentence.\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.3. Testing a POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Prepare Training & Test Splits as 80%/20%\n",
    "import math\n",
    "\n",
    "total_size = len(treebank.tagged_sents())\n",
    "train_indx = math.ceil(total_size * 0.8)\n",
    "trn_data = treebank.tagged_sents(tagset='universal')[:train_indx]\n",
    "tst_data = treebank.tagged_sents(tagset='universal')[train_indx:]\n",
    "\n",
    "print(\"Total: {}; Train: {}; Test: {}\".format(total_size, len(trn_data), len(tst_data)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4. Rule-based POS-Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# rule-based tagging\n",
    "from nltk.tag import RegexpTagger\n",
    "\n",
    "# rules from NLTK adapted to Universal Tag Set & extended\n",
    "rules = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                # gerunds\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'[\\.,!\\?:;\\'\"]', '.'),            # punctuation (extension) \n",
    "    (r'.*', 'NOUN')                     # nouns (default)\n",
    "]\n",
    "\n",
    "re_tagger = RegexpTagger(rules)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(re_tagger.tag(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = re_tagger.accuracy(tst_data)\n",
    "\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Exercise\n",
    "\n",
    "- Extend rule-set of RegexpTagger to handle close-class words (similar to punctuation & DET):\n",
    "\n",
    "    - prepositions (ADP)\n",
    "        - in, among, of, above, etc (add as many you want)\n",
    "    - particles (PRT)\n",
    "        - to, well, up, now, not (add as many you want)\n",
    "    - pronouns (PRON)\n",
    "        - I, you, he, she, it, they, we (add as many you want)\n",
    "    - conjunctions (CONJ)\n",
    "        - and, or, but, while, when, since (add as many you want)\n",
    "\n",
    "- Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "aug_rules = [\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'NUM'),   # cardinal numbers\n",
    "    (r'(The|the|A|a|An|an)$', 'DET'),   # articles\n",
    "    (r'.*able$', 'ADJ'),                # adjectives\n",
    "    (r'.*ness$', 'NOUN'),               # nouns formed from adjectives\n",
    "    (r'.*ly$', 'ADV'),                  # adverbs\n",
    "    (r'.*s$', 'NOUN'),                  # plural nouns\n",
    "    (r'.*ing$', 'VERB'),                # gerunds\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'.*ed$', 'VERB'),                 # past tense verbs\n",
    "    (r'[\\.,!\\?:;\\'\"]', '.'),            # punctuation (extension) \n",
    "    (r'(In|in|Among|among|Above|above|as|As)$', 'ADP'),   # prepositions\n",
    "    (r'(to|To|well|Well|Up|up|Not|not|Now|now)$', 'PRT'),   # particles\n",
    "    (r'(I|you|You|He|he|She|she|It|it|They|they|We|we)$', 'PRON'),   # pronouns\n",
    "    (r'(and| or|But|but|while|since)$', 'CONJ'),# conjunctions\n",
    "    (r'.*', 'NOUN'),                     # nouns (default)\n",
    "]\n",
    "aug_re_tagger = RegexpTagger(aug_rules)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(re_tagger.tag(s)))\n",
    "    break\n",
    "\n",
    "accuracy = aug_re_tagger.accuracy(tst_data)\n",
    "\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 3.3.4. Training HMM POS Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# training hmm on treebank\n",
    "import nltk.tag.hmm as hmm\n",
    "\n",
    "hmm_model = hmm.HiddenMarkovModelTrainer()\n",
    "hmm_tagger = hmm_model.train(trn_data)\n",
    "\n",
    "# tagging sentences in test set\n",
    "for s in treebank.sents()[:train_indx]:\n",
    "    print(\"INPUT: {}\".format(s))\n",
    "    print(\"TAG  : {}\".format(hmm_tagger.tag(s)))\n",
    "    print(\"PATH : {}\".format(hmm_tagger.best_path(s)))\n",
    "    break\n",
    "    \n",
    "# evaluation\n",
    "accuracy = hmm_tagger.accuracy(tst_data)\n",
    "\n",
    "print(\"Accuracy: {:6.4f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lab Exercise: Comparative Evaluation of NLTK Tagger and Spacy Tagger\n",
    "\n",
    "\n",
    "Train and evaluate NgramTagger\n",
    "- experiment with different tagger parameters\n",
    "- some of them have *cut-off*\n",
    "\n",
    "Evaluate `spacy` POS-tags on the same test set\n",
    "- create mapping from spacy to NLTK POS-tags \n",
    "    - SPACY list https://universaldependencies.org/u/pos/index.html\n",
    "    - NLTK list https://github.com/slavpetrov/universal-pos-tags\n",
    "- convert output to the required format (see format above)\n",
    "    - flatten into a list\n",
    "- evaluate using `accuracy` from `nltk.metrics` \n",
    "    - [link](https://www.nltk.org/_modules/nltk/metrics/scores.html#accuracy)\n",
    "        \n",
    "**Dataset**: treebank <br>\n",
    "**Expected output**: NLTK: Accuracy SPACY: Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "# See abore for further details\n",
    "mapping_spacy_to_NLTK = {\n",
    "    \"ADJ\": \"ADJ\",\n",
    "    \"ADP\": \"ADP\",\n",
    "    \"ADV\": \"ADV\",\n",
    "    \"AUX\": \"VERB\",\n",
    "    \"CCONJ\": \"CONJ\",\n",
    "    \"DET\": \"DET\",\n",
    "    \"INTJ\": \"X\",\n",
    "    \"NOUN\": \"NOUN\",\n",
    "    \"NUM\": \"NUM\",\n",
    "    \"PART\": \"PRT\",\n",
    "    \"PRON\": \"PRON\",\n",
    "    \"PROPN\": \"NOUN\",\n",
    "    \"PUNCT\": \".\",\n",
    "    \"SCONJ\": \"CONJ\",\n",
    "    \"SYM\": \"X\",\n",
    "    \"VERB\": \"VERB\",\n",
    "    \"X\": \"X\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
