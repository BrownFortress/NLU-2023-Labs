{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Word Sense Disambiguation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Objectives\n",
    "\n",
    "- Understanding\n",
    "    - Lexical Relations\n",
    "    - Word senses in WordNet\n",
    "    - Semantic Similarity (in WordNet)\n",
    "    \n",
    "- Learning how to disambiguate word senses\n",
    "    - Dictionary-based Word Sense Disambiguation with WordNet\n",
    "        - Lesk Algorithm\n",
    "        - Graph-based Methods\n",
    "    - Supervised Word Sense Disambiguation\n",
    "        - Feature Extractions for Word Sense Classification\n",
    "            - Bag-of-Words\n",
    "            - Collocational Features\n",
    "        - Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Recommended Reading\n",
    "- Dan Jurafsky and James H. Martin. [__Speech and Language Processing__ (SLP)](https://web.stanford.edu/~jurafsky/slp3/) (3rd ed. draft)\n",
    "- Steven Bird, Ewan Klein, and Edward Loper. [__Natural Language Processing with Python__ (NLTK)](https://www.nltk.org/book/)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covered Material\n",
    "\n",
    "- SLP\n",
    "    - [Chapter 18: Word Senses and WordNet](https://web.stanford.edu/~jurafsky/slp3/18.pdf)\n",
    "- NLTK\n",
    "    - [Chapter 2: Accessing Text Corpora and Lexical Resources](https://www.nltk.org/book/ch02.html)\n",
    "        - Section 5: WordNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Requirements\n",
    "\n",
    "- [NLTK](https://www.nltk.org/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Word Sense Disambiguation\n",
    "\n",
    "In natural language processing, word sense disambiguation (WSD) is the problem of determining which \"sense\" (meaning) of a word is activated by the use of the word in a particular context, a process which appears to be largely unconscious in people. \n",
    "\n",
    "WSD is a natural classification problem: \n",
    "Given a word and its possible senses, as defined by a dictionary, the objective of WSD is to classify an occurrence of the word in context into one or more of its sense classes. The features of the context (such as neighboring words) provide are used as features for classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- Human Language is ambiguous\n",
    "    - Syntacting ambiguity\n",
    "        - Resolved by POS-tagging\n",
    "        - Syntactic Parsing\n",
    "    - Lexical ambiguity\n",
    "        - Resolved by Word Sense Disambiguation\n",
    "        - Semantics work at level of word __senses__, not __words__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Example__:\n",
    "- NOUN\n",
    "    - 'they pulled the canoe up on the __bank__'\n",
    "    - 'he cashed a check at the __bank__'\n",
    "- VERB\n",
    "    - 'the plane __banked__ steeply'\n",
    "    - '__bank__ on your good education'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.1. Task Variants\n",
    "- __Lexical sample subtask__: only a small selection of words has to be disambiguated\n",
    "    - Supervised machine learning: train a classifier for each word\n",
    "- __All words subtask__: each and every content word in the test corpus has to be disambiguated.\n",
    "    - Data sparseness issue, can't train a classifier for each word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### 1.2. Evaluation\n",
    "Precision, recall, F1-measure against gold standard data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 1.3. Lexical Relations\n",
    "Relation between word senses.\n",
    "\n",
    "- __Homonymy__: senses are not related *(same spelling different meaning)*\n",
    "- __Polysemy__: senses are related *(same spelling different but related meaning)*\n",
    "- __Metonymy__: a thing or concept is referred to by the name of something closely associated with that thing or concept. (e.g. *Rome* for Italian Government)\n",
    "    - It is a subtype of polysemy\n",
    "\n",
    "\n",
    "- __Synonymy__: senses are identical *(different spelling same meaning)*\n",
    "- __Antonymy__: senses are opposite\n",
    "- __Hyponymy__ (specific) (*car is hyponym of vehicle*) and __Hypernymy__ (generic): class-inclusion relationships (*vehicle is hypernymy of car*)\n",
    "- __Meronymy__ (part)(*wheel is part of car*) and __Holonymy__ (whole): the part-whole relation (*car ia holonymy of wheel*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "[WordNet](https://wordnet.princeton.edu/) is a lexical database of semantic relations between words that links words into semantic relations including synonyms, hyponyms, and meronyms. \n",
    "\n",
    "Nouns, verbs, adjectives and adverbs are grouped into sets of cognitive synonyms (synsets), each expressing a distinct concept. Synsets are interlinked by means of conceptual-semantic and lexical relations. \n",
    "\n",
    "\n",
    "__Summary__\n",
    "\n",
    "WordNet is a:\n",
    "- Graph (4 graphs for each of nouns, verbs, adjectives, and adverbs)\n",
    "- Nodes are Synsets (synonyms)\n",
    "- Labeled Edges are Relations between Synsets\n",
    "\n",
    "    - PART-OF\n",
    "    - KIND-OF (IS-A)\n",
    "    - ENTAILMENT\n",
    "    - ANTONYMY\n",
    "    \n",
    "> Senses in WordNet are generally ordered from most to least frequently used, with the most common sense numbered 1.\n",
    "\n",
    "[WordNet Site](https://wordnet.princeton.edu/documentation/wndb5wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from pprint import pprint\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's import WordNet\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# printing senses of a word (including honomymy & polysemy)\n",
    "senses = wordnet.synsets('bank')\n",
    "print(senses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.1. Synset \n",
    "The entity `bank.n.01` is called a __synset__, or \"synonym set\", a collection of synonymous words (or \"lemmas\").\n",
    "\n",
    "The name is composed as `<lemma>.<pos>.<number>` string where: \n",
    "- `<lemma>` is the word's morphological stem \n",
    "- `<pos>` is one of the module attributes `ADJ`, `ADJ_SAT`, `ADV`, `NOUN` or `VERB` \n",
    "- `<number>` is the sense number, counting from `0`\n",
    "\n",
    "Part-of-speech tags appear as below:\n",
    "\n",
    "| POS | in Synset Name |\n",
    "|:----|:---------------|\n",
    "| `wn.NOUN`    | `n`\n",
    "| `wn.VERB`    | `v`\n",
    "| `wn.ADV`     | `r`\n",
    "| `wn.ADJ`     | `a`\n",
    "| `wn.ADJ_SAT` | `s` (satelite adjective, ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# it's possible to provide part of speech to filter senses as well\n",
    "senses = wordnet.synsets('bank', wordnet.NOUN)\n",
    "pprint(senses)\n",
    "print('')\n",
    "print(\"POS:\",senses[0].pos())  # part-of-speech tag of a synset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Each word of a synset can have several meanings, synset represents the single meaning that is common to all words in it. \n",
    "Each synset has a __definition__ and __example__ sentences, that can be accessed using `definition()` and `examples()` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(senses[0].definition())\n",
    "print(senses[0].examples())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.2. Lemmatization\n",
    "`wordnet.synsets()` method expects a word to be a __lemma__, i.e. canonical (dictionary) form of a word. In case it does find a word in WordNet, it internally applies morphological transformation rules to strip off affixes untill it finds the form.\n",
    "\n",
    "```\n",
    "MORPHOLOGICAL_SUBSTITUTIONS = {\n",
    "    NOUN: [(\"s\", \"\"), (\"ses\", \"s\"), (\"ves\", \"f\"), (\"xes\", \"x\"), (\"zes\", \"z\"), \n",
    "           (\"ches\", \"ch\"), (\"shes\", \"sh\"), (\"men\", \"man\"), (\"ies\", \"y\"), ],\n",
    "    VERB: [(\"s\", \"\"), (\"ies\", \"y\"), (\"es\", \"e\"), (\"es\", \"\"), \n",
    "           (\"ed\", \"e\"), (\"ed\", \"\"), \n",
    "           (\"ing\", \"e\"), (\"ing\", \"\"), ],\n",
    "    ADJ: [(\"er\", \"\"), (\"est\", \"\"), (\"er\", \"e\"), (\"est\", \"e\")],\n",
    "    ADV: [],\n",
    "}\n",
    "```\n",
    "\n",
    "Those could be applied calling `wordnet.morphy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "wordnet.morphy('banked')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Note that only verb synsets are listed\n",
    "wordnet.synsets('banked') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`wordnet.morphy()` is the basis of the WordNet-based Lemmatizer in NLTK. The Lemmatizer can be used as follows, optionally providing a part-of-speech (default is NOUN)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem = WordNetLemmatizer()\n",
    "print(lem.lemmatize('banks'))\n",
    "print(lem.lemmatize('banked', pos=wordnet.VERB))\n",
    "print(lem.lemmatize('bnked', pos=wordnet.VERB))  # returns the word itself if it cannot find it"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 2.2.1. Lemmas in WordNet\n",
    "In WordNet __Lemma__ is a pairing of words with a synset: `bank.n.01` + `bank`.\n",
    "\n",
    "From a __synset__ we can get:\n",
    "- all its lemmas (`lemmas()`)\n",
    "- all its lemma names (`lemma_names()`)\n",
    "\n",
    "From a __lemma__ we can get:\n",
    "- its name (`name()`)\n",
    "- synset it belongs to (`synset()`)\n",
    "\n",
    "Similar to synsets, we can get all lemmas for a word as well using `lemmas()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lemmas = wordnet.lemmas('bank')\n",
    "pprint(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Look up lemma directly\n",
    "lemma = wordnet.lemma('bank.n.01.bank')\n",
    "print(lemma.name())\n",
    "print(lemma.synset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Get Lemmas of a synset\n",
    "print(senses[0].lemmas())\n",
    "print(senses[0].lemma_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 2.3. Lexical Relations beween Synsets\n",
    "\n",
    "WordNet synsets correspond to abstract concepts that are linked together in a hierarchy from very general (such as `Entity`, `State`, `Event` a.k.a *unique beginners* or *root synsets*) to very specific. \n",
    "\n",
    "Hypernymy/Hyponymy relations are used to navigate the taxonomy using `hypernyms()` and `hyponyms()` methods.\n",
    "\n",
    "- `hypernym_paths()` gets the lists of the hypernym synsets to the root (several paths are possible)\n",
    "- `root_hypernyms()` gets the root synset\n",
    "- `hypernym_distances()` get the path(s) from the synset to the root, counting the distance of each node from the initial node on the way\n",
    "\n",
    "- `max_depth()` returns the length of the longest hypernym path from the synset to the root.\n",
    "- `min_depth()` returns the length of the shortest hypernym path from the synset to the root."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "pprint(senses[0].hyponyms())\n",
    "pprint(senses[0].hypernyms())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# getting paths to the root of the taxonomy\n",
    "pprint(senses[0].hypernym_paths())\n",
    "# getting hypernyms with distances\n",
    "pprint(senses[0].hypernym_distances())\n",
    "# getting the root node\n",
    "pprint(senses[0].root_hypernyms())\n",
    "print(senses[0].max_depth())\n",
    "print(senses[0].min_depth())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Read about other relations defined for synsets and lemmas in the [NLTK documentation](http://www.nltk.org/api/nltk.corpus.reader.html#module-nltk.corpus.reader.wordnet).\n",
    "\n",
    "__Whole description of WordNet methods and structure is out of the scope of the lab.__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 3. Lesk Algorithm\n",
    "\n",
    "> \"What we try is to guess the correct word sense by counting overlaps between dictionary definitions of the various senses.\" \n",
    "\n",
    "(Lesk, Michael. \"Automatic sense disambiguation using machine readable dictionaries: how to tell a pine cone from an ice cream cone.\" Proceedings of the 5th Annual International Conference on Systems Documentation. ACM, 1986.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.1. Simplified Lesk Algorithm\n",
    "\n",
    "Kilgarriff and Rosenzweig (2000) [English SENSEVAL](http://www.lrec-conf.org/proceedings/lrec2000/pdf/8.pdf)\n",
    "\n",
    "```\n",
    "For each sense s of that word,\n",
    "    set weight(s) to zero.\n",
    "\n",
    "Identify set of unique words W in surrounding sentence.\n",
    "\n",
    "For each word w in W,\n",
    "    for each sense s,\n",
    "        if w occurs in the definition or example sentences of s,\n",
    "            add weight(w) to weight(s).\n",
    "Choose sense with greatest weight(s)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> `weight(w)` is defined as the [inverse document frequency](https://en.wikipedia.org/wiki/Tfâ€“idf) (IDF) of the word `w` over the definitions and example sentences in the dictionary. The IDF of a word `w` is computed as `-log(p(w))`, where `p(w)` is estimated as the fraction of dictionary \"documents\" -- definition or examples -- which contain the word. \n",
    "\n",
    "$$ IDF = -\\log {|\\{d \\in D : w \\in d\\}| \\over |D|}$$\n",
    "\n",
    "where `w` is the word and `D` is the set of documents\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.2. Lesk Plus Corpus\n",
    "\n",
    "> LESK-PLUS-CORPUS is as LESK, but also considers the tagged training data, so can be compared with supervised\n",
    "systems. For each word in the sentence containing the test item, it tests whether `w` occurs in the dictionary entry or corpus instances for each candidate sense.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.3. Simple Lesk with Equal Weights\n",
    "\n",
    "If all words are equally weighted, we compute an overlap between the definitions and example (signature) with the words in the context.\n",
    "The algorithm becomes simpler.\n",
    "\n",
    "```\n",
    "function SIMPLIFIED LESK(word, sentence) returns best sense of word\n",
    "    best-sense := most frequent sense for word (i.e. first in WordNet)\n",
    "    max-overlap := 0\n",
    "    context := set of words in sentence\n",
    "    for each sense in senses of word do\n",
    "        signature := set of words in gloss and examples of sense\n",
    "        overlap := COMPUTE_OVERLAP(signature, context)\n",
    "        if overlap > max-overlap then\n",
    "            max-overlap := overlap\n",
    "            best-sense := sense\n",
    "    end\n",
    "return(best-sense)\n",
    "```\n",
    "\n",
    "```\n",
    "COMPUTE OVERLAP returns the number of words in common between two sets.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Improvements\n",
    "\n",
    "- Removing stop words\n",
    "    - IDF makes them weight less in Simplified Lesk by Kilgarriff and Rosenzweig (2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.4. Using Lesk in NLTK\n",
    "NLTK provide the implementation of the Lesk Algorithm is [`wsd` module](https://www.nltk.org/_modules/nltk/wsd.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk\n",
    "\n",
    "sense = lesk('Jane sat on the sloping bank of a river beside the water'.split(), 'bank')\n",
    "print(sense)\n",
    "print(sense.definition())\n",
    "\n",
    "# possible to specify the POS\n",
    "print(lesk('Jane sat on the sloping bank of a river beside the water'.split(), \n",
    "           'bank', \n",
    "           pos=wordnet.NOUN))\n",
    "\n",
    "# possible to specify the synsets to choose from\n",
    "print(lesk('Jane sat on the sloping bank of a river beside the water'.split(), \n",
    "           'bank', \n",
    "           synsets=wordnet.synsets('riverbank')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3.5. Alternative Implementations of Lesk in `pywsd`\n",
    "\n",
    "[`pywsd` library](https://github.com/alvations/pywsd) provides several variants of the Lesk algorithm.\n",
    "\n",
    "\n",
    "\n",
    "- Original Lesk (Lesk, 1986) -- also *simplified*\n",
    "- Adapted/Extended Lesk (Banerjee and Pederson, 2002/2003)\n",
    "- Simple Lesk (with definition, example(s) and hyper+hyponyms)\n",
    "- Cosine Lesk (use cosines to calculate overlaps instead of using raw counts)\n",
    "\n",
    "Unfortunatelly, it has some compatibility issues. However, can be consulted for implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercises\n",
    "Even though NLTK states that it implements Original Lesk Algorithm, in fact it is a Simplified Lesk Algorithm, that doesn't consider examples, and computes overlaps like the original. \n",
    "\n",
    "In the original algorithm context is computed differently. <mark style=\"background-color: rgba(0, 255, 0, 0.2)\">Instead of comparing a target word's signature with the context words, the target signature is compared with the signatures of each of the context words. </mark>\n",
    "\n",
    "Implement the Original Lesk Algorithm (modifying NLTK's, see pseudocode above)\n",
    "Todo list:\n",
    "- Complete lesk simplified\n",
    "- Preprocessing:\n",
    "    - compute pos-tag with `nltk.pos_tag`\n",
    "    - remove stopwords\n",
    "        - `from nltk.corpus import stopwords`\n",
    "        - `stopwords.words('english')`\n",
    "\n",
    "- take the majority decision (the sense predicted most frequently)\n",
    "\n",
    "POS tags reminder:\n",
    "\n",
    "| POS | in Synset Name |\n",
    "|:----|:---------------|\n",
    "| `wn.NOUN`    | `n`\n",
    "| `wn.VERB`    | `v`\n",
    "| `wn.ADV`     | `r`\n",
    "| `wn.ADJ`     | `a`\n",
    "| `wn.ADJ_SAT` | `s` (satelite adjective, ignore)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "def preprocess(text):\n",
    "    mapping = {\"NOUN\": wordnet.NOUN, \"VERB\": wordnet.VERB, \"ADJ\": wordnet.ADJ, \"ADV\": wordnet.ADV}\n",
    "    sw_list = stopwords.words('english')\n",
    "    \n",
    "    lem = WordNetLemmatizer()\n",
    "    \n",
    "    # tokenize, if input is text\n",
    "    tokens = nltk.word_tokenize(text) if type(text) is str else text\n",
    "    # pos-tag\n",
    "    tagged = nltk.pos_tag(tokens, tagset=\"universal\")\n",
    "    # lowercase\n",
    "    tagged = [(w.lower(), p) for w, p in tagged]\n",
    "    # optional: remove all words that are not NOUN, VERB, ADJ, or ADV (i.e. no sense in WordNet)\n",
    "    tagged = [(w, p) for w, p in tagged if p in mapping]\n",
    "    # re-map tags to WordNet (return orignal if not in-mapping, if above is not used)\n",
    "    tagged = [(w, mapping.get(p, p)) for w, p in tagged]\n",
    "    # remove stopwords\n",
    "    tagged = [(w, p) for w, p in tagged if w not in sw_list]\n",
    "    # lemmatize\n",
    "    tagged = [(w, lem.lemmatize(w, pos=p), p) for w, p in tagged]\n",
    "    # unique the list\n",
    "    tagged = list(set(tagged))\n",
    "    return tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sense_definitions(context):\n",
    "    # input is text or list of strings\n",
    "    lemma_tags = preprocess(context)\n",
    "    # let's get senses for each\n",
    "    senses = [(w, wordnet.synsets(l, p)) for w, l, p in lemma_tags]\n",
    "    \n",
    "    # let's get their definitions\n",
    "    definitions = []\n",
    "    for raw_word, sense_list in senses:\n",
    "        if len(sense_list) > 0:\n",
    "            # let's tokenize, lowercase & remove stop words \n",
    "            def_list = []\n",
    "            for s in sense_list:\n",
    "                defn = s.definition()\n",
    "                # let's use the same preprocessing\n",
    "                tags = preprocess(defn)\n",
    "                toks = [l for w, l, p in tags]\n",
    "                def_list.append((s, toks))\n",
    "            definitions.append((raw_word, def_list))\n",
    "    return definitions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_sense(words, sense_list):\n",
    "    # get top sense from the list of sense-definition tuples\n",
    "    # assumes that words and definitions are preprocessed identically\n",
    "    val, sense = max((len(set(words).intersection(set(defn))), ss) for ss, defn in sense_list)\n",
    "    return val, sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "def lesk_simplified(context_sentence, ambiguous_word, pos=None, synsets=None):\n",
    "    context = set(context_sentence)\n",
    "    \n",
    "    if synsets is None:\n",
    "        synsets = wordnet.synsets(ambiguous_word)\n",
    "    if pos:\n",
    "        synsets = [ss for ss in synsets if str(ss.pos()) == pos]\n",
    "\n",
    "    if not synsets:\n",
    "        return None\n",
    "    # Measure the overlap between context and definitions\n",
    "    _, sense = max(\n",
    "        (len(context.intersection(ss.definition().split())), ss) for ss in synsets\n",
    "    )\n",
    "\n",
    "    return sense\n",
    "\n",
    "def original_lesk(context_sentence, ambiguous_word, pos=None, synsets=None, majority=False):\n",
    "\n",
    "    context_senses = get_sense_definitions(set(context_sentence)-set([ambiguous_word]))\n",
    "    if synsets is None:\n",
    "        synsets = get_sense_definitions(ambiguous_word)[0][1]\n",
    "\n",
    "    if pos:\n",
    "        synsets = [ss for ss in synsets if str(ss[0].pos()) == pos]\n",
    "\n",
    "    if not synsets:\n",
    "        return None\n",
    "    scores = []\n",
    "    # print(synsets)\n",
    "    for senses in context_senses:\n",
    "        for sense in senses[1]:\n",
    "            scores.append(get_top_sense(sense[1], synsets))\n",
    "            \n",
    "    if len(scores) == 0:\n",
    "        return synsets[0][0]\n",
    "    \n",
    "    if majority:\n",
    "        filtered_scores = [x[1] for x in scores if x[0] != 0]\n",
    "        if len(filtered_scores) > 0:\n",
    "            best_sense = Counter(filtered_scores).most_common(1)[0][0]\n",
    "        else:\n",
    "            # Almost random selection\n",
    "            best_sense = Counter([x[1] for x in scores]).most_common(1)[0][0]\n",
    "    else:\n",
    "        _, best_sense = max(scores)\n",
    "    return best_sense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jane sat on the sloping bank of a river beside the water\".split()\n",
    "word = \"bank\"\n",
    "print(\"Sense from lesk original\", original_lesk(text, word, majority=True))\n",
    "print(\"Sense from lesk simplified\", lesk_simplified(text, word))\n",
    "print(\"Sense from lesk NLTK\", lesk(text, word))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 4. Graph-based Methods on WordNet for WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 4.1. Maximum Relatedness Disambiguation\n",
    "\n",
    "Pedersen et al. (2003) [Maximizing Semantic Relatedness to Perform Word Sense Disambiguation](https://www.d.umn.edu/~tpederse/Pubs/max-sem-relate.pdf)\n",
    "\n",
    "\n",
    "```\n",
    "w = words\n",
    "\n",
    "foreach sense s[t][i] of target word w[t]$\n",
    "    set score[i] = 0\n",
    "    foreach word w[j] in window of context\n",
    "        skip to next word if j == t\n",
    "\n",
    "        foreach sense s[j][k] of w[j]\n",
    "            temp_score[j] = relatedness(s[t][i], s[j][k])\n",
    "\n",
    "        winning_score = highest score in array temp_score[]\n",
    "\n",
    "        if (winning_score > threshold)\n",
    "            set score[i] = score[i] + winning_score\n",
    "            \n",
    "return i, such that score[i] >= score[j] , for all j, 1 <= j <= n, n = number of words in sentence\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.1.1. How do we define relatedness?\n",
    "\n",
    "- Similar words are near-synonyms: e.g. *car*, *motorcycle*\n",
    "- Related words can be related any way: e.g. *car*, *fuel*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Thesaurus-based similarity\n",
    "    - words have similar definitions (Lesk)\n",
    "    - words are close to each other in hypernym hierarchy (graph-based)\n",
    "- Distributional similarity\n",
    "    - do words apprear in similar distributional contexts\n",
    "    - __distributional (vector) semantics__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the similarity between *dime* and *nickel* and between *nickel* and *credit card*: \n",
    "\n",
    "![](https://i.postimg.cc/tJn0NMgm/Screenshot-2023-01-03-at-10-26-20.png)\n",
    "\n",
    "[*Original source (Resnik, 1995)*](https://arxiv.org/pdf/cmp-lg/9511007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.1.2. Path-based Similarity\n",
    "\n",
    "Two concepts (senses/synsets) are similar if they are near each other in the thesaurus hierarchy\n",
    "- have a __short path__ between them (1 + number of edges between nodes)\n",
    "- path to themselves has distance `1`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### NLTK Path Based Metrics\n",
    "\n",
    "- `synset1.path_similarity(synset2)`: Return a score denoting how similar two word senses are, based on the __shortest path__ that connects the senses in the is-a (hypernym/hypnoym) taxonomy. The score is in the range 0 to 1, computed as `1/path_length`\n",
    "- `synset1.lch_similarity(synset2)`: __Leacock-Chodorow Similarity__: Return a score denoting how similar two word senses are, based on the shortest path that connects the senses and the maximum depth of the taxonomy in which the senses occur. The relationship is given as `-log(p/2d)` where `p` is the shortest path length and `d` the taxonomy depth ( i.e. the number of synsets).\n",
    "- `synset1.wup_similarity(synset2)`: __Wu-Palmer Similarity__: Return a score denoting how similar two word senses are, based on the depth of the two senses in the taxonomy and that of their __Least Common Subsumer__ (most specific ancestor node)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "bank_r = wordnet.synsets('bank')[0]\n",
    "bank_f = wordnet.synsets('bank')[1]\n",
    "river = wordnet.synsets('river')[0]\n",
    "school = wordnet.synsets('school')[0]\n",
    "\n",
    "print(river.definition())\n",
    "print(bank_r.definition())\n",
    "print(bank_f.definition())\n",
    "print(school.definition())\n",
    "\n",
    "print(bank_r.path_similarity(river))\n",
    "print(bank_f.path_similarity(river))\n",
    "\n",
    "print(bank_f.path_similarity(school))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(bank_r.lch_similarity(river))\n",
    "print(bank_f.lch_similarity(river))\n",
    "print(bank_f.lch_similarity(school))\n",
    "\n",
    "print(bank_r.wup_similarity(river))\n",
    "print(bank_f.wup_similarity(river))\n",
    "print(bank_f.wup_similarity(school))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 4.1.3. Information Content Similarity\n",
    "\n",
    "- Path-based similarity issues\n",
    "    - each edge is has equal distance; however nodes high in hierarchy are more abstract\n",
    "- Better metric\n",
    "    - each edge has independent cost\n",
    "    - nodes connected through higher-level (abstract) nodes are less similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### Information Content\n",
    "- Trained on a corpus\n",
    "- `P(c)` the probability of a concept `c` in a corpus\n",
    "    $$ P(c) = \\frac{\\sum_{w \\in \\text{words}(c)}\\text{count}(c)}{N}$$\n",
    "    where $\\text{words}(c)$ is set of all words that are children of concept $c$. $N$ is the total number of nouns observed. \n",
    "- All words are members of the root node (e.g. `Entity`); thus, `P(root) = 1`\n",
    "    - In NLTK it's the opposite P(root) = 0 \n",
    "- The lower a node in hierarchy, the lower its probability\n",
    "\n",
    "- Information Content $$IC(c) = -log(P(c))$$\n",
    "- Most Informative Subsumer (Lowest Common Subsumer) $LCS(c_1, c_2)$ is the lowest node in the hierarchy subsuming both $c_1$ and $c_2$\n",
    "\n",
    "If you are further interested in this you should read the paper of [Resnik](https://arxiv.org/pdf/cmp-lg/9511007)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "##### NLTK Information Content Based Metrics\n",
    "- `res_similarity(other, ic)`: __Resnik Similarity__: Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node). Computed as `IC(lcs) = -log(P(lcs))`.\n",
    "- `lin_similarity(other, ic)`: __Lin Similarity__: Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets. The relationship is given by the equation `2 * IC(lcs) / (IC(s1) + IC(s2))`.\n",
    "- `jcn_similarity(other, ic)`: __Jiang-Conrath Similarity__: Return a score denoting how similar two word senses are, based on the Information Content (IC) of the Least Common Subsumer (most specific ancestor node) and that of the two input Synsets. The relationship is given by the equation `1 / (IC(s1) + IC(s2) - 2 * IC(lcs))`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# getting pre-computed ic of the semcor corpus (large sense tagged corpus)\n",
    "from nltk.corpus import wordnet_ic\n",
    "nltk.download('wordnet_ic')\n",
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(bank_r.res_similarity(river, semcor_ic))\n",
    "print(bank_f.res_similarity(river, semcor_ic))\n",
    "print(bank_f.res_similarity(school, semcor_ic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(bank_r.lin_similarity(bank_r, semcor_ic))\n",
    "print(bank_f.lin_similarity(river, semcor_ic))\n",
    "print(bank_f.lin_similarity(school, semcor_ic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "print(bank_r.jcn_similarity(bank_r, semcor_ic))\n",
    "print(bank_f.jcn_similarity(river, semcor_ic))\n",
    "print(bank_f.jcn_similarity(school, semcor_ic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "Extend Lesk algorithm (function) to use similarity metrics instead of just overlaps\n",
    "- add a keyword argument to allow different metrics\n",
    "\n",
    "Complete the Predersen algorithm with the similiratiy metrics\n",
    "- compare the output of the two algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semcor_ic = wordnet_ic.ic('ic-semcor.dat')\n",
    "def get_top_sense_sim(context_sense, sense_list, similarity):\n",
    "    # get top sense from the list of sense-definition tuples\n",
    "    # assumes that words and definitions are preprocessed identically\n",
    "    scores = []\n",
    "    for sense in sense_list:\n",
    "        ss = sense[0]\n",
    "        if similarity == \"path\":\n",
    "            try:\n",
    "                scores.append((context_sense.path_similarity(ss), ss))\n",
    "            except:\n",
    "                scores.append((0, ss))    \n",
    "        elif similarity == \"lch\":\n",
    "            try:\n",
    "                scores.append((context_sense.lch_similarity(ss), ss))\n",
    "            except:\n",
    "                scores.append((0, ss))\n",
    "        elif similarity == \"wup\":\n",
    "            try:\n",
    "                scores.append((context_sense.wup_similarity(ss), ss))\n",
    "            except:\n",
    "                scores.append((0, ss))\n",
    "        elif similarity == \"resnik\":\n",
    "            try:\n",
    "                scores.append((context_sense.res_similarity(ss, semcor_ic), ss))\n",
    "            except:\n",
    "                scores.append((0, ss))\n",
    "        elif similarity == \"lin\":\n",
    "            try:\n",
    "                scores.append((context_sense.lin_similarity(ss, semcor_ic), ss))\n",
    "            except:\n",
    "                scores.append((0, ss))\n",
    "        elif similarity == \"jiang\":\n",
    "            try:\n",
    "                scores.append((context_sense.jcn_similarity(ss, semcor_ic), ss))\n",
    "            except:\n",
    "                scores.append((0, ss))\n",
    "        else:\n",
    "            print(\"Similarity metric not found\")\n",
    "            return None\n",
    "    val, sense = max(scores)\n",
    "    return val, sense\n",
    "\n",
    "def lesk_similarity(context_sentence, ambiguous_word, similarity=\"resnik\", pos=None, \n",
    "                    synsets=None, majority=True):\n",
    "    context_senses = get_sense_definitions(set(context_sentence) - set([ambiguous_word]))\n",
    "    \n",
    "    if synsets is None:\n",
    "        synsets = get_sense_definitions(ambiguous_word)[0][1]\n",
    "\n",
    "    if pos:\n",
    "        synsets = [ss for ss in synsets if str(ss[0].pos()) == pos]\n",
    "\n",
    "    if not synsets:\n",
    "        return None\n",
    "    \n",
    "    scores = []\n",
    "    \n",
    "    # Here you may have some room for improvement\n",
    "    # For instance instead of using all the definitions from the context\n",
    "    # you pick the most common one of each word (i.e. the first)\n",
    "    for senses in context_senses:\n",
    "        for sense in senses[1]:\n",
    "            scores.append(get_top_sense_sim(sense[0], synsets, similarity))\n",
    "            \n",
    "    if len(scores) == 0:\n",
    "        return synsets[0][0]\n",
    "    \n",
    "    if majority:\n",
    "        filtered_scores = [x[1] for x in scores if x[0] != 0]\n",
    "        if len(filtered_scores) > 0:\n",
    "            best_sense = Counter(filtered_scores).most_common(1)[0][0]\n",
    "        else:\n",
    "            # Almost random selection\n",
    "            best_sense = Counter([x[1] for x in scores]).most_common(1)[0][0]\n",
    "    else:\n",
    "        _, best_sense = max(scores)\n",
    "    \n",
    "    return best_sense\n",
    "\n",
    "def pedersen(context_sentence, ambiguous_word, similarity=\"resnik\", pos=None, \n",
    "                    synsets=None, threshold=0.1):\n",
    "    \n",
    "    context_senses = get_sense_definitions(set(context_sentence) - set([ambiguous_word]))\n",
    "\n",
    "    if synsets is None:\n",
    "        synsets = get_sense_definitions(ambiguous_word)[0][1]\n",
    "\n",
    "    if pos:\n",
    "        synsets = [ss for ss in synsets if str(ss[0].pos()) == pos]\n",
    "\n",
    "    if not synsets:\n",
    "        return None\n",
    "    \n",
    "    synsets_scores = {}\n",
    "    for ss_tup in synsets:\n",
    "        ss = ss_tup[0]\n",
    "        if ss not in synsets_scores:\n",
    "            synsets_scores[ss] = 0\n",
    "        for senses in context_senses:\n",
    "            scores = []\n",
    "            for sense in senses[1]:\n",
    "                if similarity == \"path\":\n",
    "                    try:\n",
    "                        scores.append((sense[0].path_similarity(ss), ss))\n",
    "                    except:\n",
    "                        scores.append((0, ss))    \n",
    "                elif similarity == \"lch\":\n",
    "                    try:\n",
    "                        scores.append((sense[0].lch_similarity(ss), ss))\n",
    "                    except:\n",
    "                        scores.append((0, ss))\n",
    "                elif similarity == \"wup\":\n",
    "                    try:\n",
    "                        scores.append((sense[0].wup_similarity(ss), ss))\n",
    "                    except:\n",
    "                        scores.append((0, ss))\n",
    "                elif similarity == \"resnik\":\n",
    "                    try:\n",
    "                        scores.append((sense[0].res_similarity(ss, semcor_ic), ss))\n",
    "                    except:\n",
    "                        scores.append((0, ss))\n",
    "                elif similarity == \"lin\":\n",
    "                    try:\n",
    "                        scores.append((sense[0].lin_similarity(ss, semcor_ic), ss))\n",
    "                    except:\n",
    "                        scores.append((0, ss))\n",
    "                elif similarity == \"jiang\":\n",
    "                    try:\n",
    "                        scores.append((sense[0].jcn_similarity(ss, semcor_ic), ss))\n",
    "                    except:\n",
    "                        scores.append((0, ss))\n",
    "                else:\n",
    "                    print(\"Similarity metric not found\")\n",
    "                    return None\n",
    "            value, sense = max(scores)\n",
    "            if value > threshold:\n",
    "                synsets_scores[sense] = synsets_scores[sense] + value\n",
    "    \n",
    "    values = list(synsets_scores.values())\n",
    "    if sum(values) == 0:\n",
    "        print('Warning all the scores are 0')\n",
    "    senses = list(synsets_scores.keys())\n",
    "    best_sense_id = values.index(max(values))\n",
    "    return senses[best_sense_id]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jane sat on the sloping bank of a river beside the water\".split()\n",
    "word = \"bank\"\n",
    "sense = original_lesk(text, word, majority=True)\n",
    "print('Original lesk', sense, sense.definition())\n",
    "sense = lesk(text, word)\n",
    "print('Symplified lesk', sense, sense.definition())\n",
    "sense = predersen(text, word, similarity=\"resnik\", threshold=0.1)\n",
    "print(\"Pedersen\", sense, sense.definition())\n",
    "sense = lesk_similarity(text, word, pos='n', similarity=\"path\")\n",
    "print('Graph-based lesk', sense, sense.definition())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 5. Evaluation on Senseval 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 5.1. Senseval Corpus\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. \n",
    "It contains data for four words: `hard`, `interest`, `line`, and `serve`. Let's use `interest` portion to illustrate evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nltk.download('senseval')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Corpus instances are stored as:\n",
    "- `context` - POS-tagged context sentence\n",
    "- `position` - index of the target word in a context sentence\n",
    "- `senses` - labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import senseval\n",
    "\n",
    "inst = senseval.instances('interest.pos')[0]\n",
    "\n",
    "print(inst.position, inst.context, inst.senses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 5.1.1. Mapping Senseval Senses to WordNet\n",
    "\n",
    "Senseval labels are not compatible with WordNet 3.0; thus, let's manually create a mapping.\n",
    "\n",
    "__Senses for *interest* in Longman Dictionary__\n",
    "- Sense 1 =  361 occurrences (15%) - readiness to give attention\n",
    "- Sense 2 =   11 occurrences (01%) - quality of causing attention to be given to\n",
    "- Sense 3 =   66 occurrences (03%) - activity, etc. that one gives attention to\n",
    "- Sense 4 =  178 occurrences (08%) - advantage, advancement or favor\n",
    "- Sense 5 =  500 occurrences (21%) - a share in a company or business\n",
    "- Sense 6 = 1252 occurrences (53%) - money paid for the use of money"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# definitions of \"interest\"'s synsets in WordNet\n",
    "iss = wordnet.synsets('interest', pos='n')\n",
    "for ss in iss:\n",
    "    print(ss, ss.definition())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create mapping from convenience\n",
    "mapping = {\n",
    "    'interest_1': 'interest.n.01',\n",
    "    'interest_2': 'interest.n.03',\n",
    "    'interest_3': 'pastime.n.01',\n",
    "    'interest_4': 'sake.n.01',\n",
    "    'interest_5': 'interest.n.05',\n",
    "    'interest_6': 'interest.n.04',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 5.1.2. Evaluation\n",
    "\n",
    "- Let's use accuracy for simplicity\n",
    "- Also demonstrating per-class precision, recall, and f-measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.scores import precision, recall, f_measure, accuracy\n",
    "\n",
    "refs = {k: set() for k in mapping.values()}\n",
    "hyps = {k: set() for k in mapping.values()}\n",
    "refs_list = []\n",
    "hyps_list = []\n",
    "\n",
    "# since WordNet defines more senses, let's restrict predictions\n",
    "synsets = [ss for ss in wordnet.synsets('interest', pos='n') if ss.name() in mapping.values()]\n",
    "\n",
    "for i, inst in enumerate(senseval.instances('interest.pos')):\n",
    "    txt = [t[0] for t in inst.context]\n",
    "    raw_ref = inst.senses[0] # let's get first sense\n",
    "    hyp = lesk_simplified(txt, txt[inst.position], synsets=synsets).name()\n",
    "    ref = mapping.get(raw_ref)\n",
    "    \n",
    "    # for precision, recall, f-measure        \n",
    "    refs[ref].add(i)\n",
    "    hyps[hyp].add(i)\n",
    "    \n",
    "    # for accuracy\n",
    "    refs_list.append(ref)\n",
    "    hyps_list.append(hyp)\n",
    "\n",
    "print(\"Acc:\", round(accuracy(refs_list, hyps_list), 3))\n",
    "\n",
    "for cls in hyps.keys():\n",
    "    p = precision(refs[cls], hyps[cls])\n",
    "    r = recall(refs[cls], hyps[cls])\n",
    "    f = f_measure(refs[cls], hyps[cls], alpha=1)\n",
    "    \n",
    "    print(\"{:15s}: p={:.3f}; r={:.3f}; f={:.3f}; s={}\".format(cls, p, r, f, len(refs[cls])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Exercise\n",
    "- Evaluate Original Lesk (your implementation on Senseval's `interest`)\n",
    "- You can also easily evalutate Lesk similarity that we have seen before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from nltk.metrics.scores import precision, recall, f_measure, accuracy\n",
    "\n",
    "refs = {k: set() for k in mapping.values()}\n",
    "hyps = {k: set() for k in mapping.values()}\n",
    "refs_list = []\n",
    "hyps_list = []\n",
    "\n",
    "# since WordNet defines more senses, let's restrict predictions\n",
    "\n",
    "synsets = []\n",
    "for ss in wordnet.synsets('interest', pos='n'):\n",
    "    if ss.name() in mapping.values():\n",
    "        defn = ss.definition()\n",
    "        tags = preprocess(defn)\n",
    "        toks = [l for w, l, p in tags]\n",
    "        synsets.append((ss,toks))\n",
    "\n",
    "for i, inst in enumerate(senseval.instances('interest.pos')):\n",
    "    txt = [t[0] for t in inst.context]\n",
    "    raw_ref = inst.senses[0] # let's get first sense\n",
    "    hyp = original_lesk(txt, txt[inst.position], synsets=synsets, majority=True).name()\n",
    "    ref = mapping.get(raw_ref)\n",
    "    \n",
    "    # for precision, recall, f-measure        \n",
    "    refs[ref].add(i)\n",
    "    hyps[hyp].add(i)\n",
    "    \n",
    "    # for accuracy\n",
    "    refs_list.append(ref)\n",
    "    hyps_list.append(hyp)\n",
    "\n",
    "print(\"Acc:\", round(accuracy(refs_list, hyps_list), 3))\n",
    "\n",
    "for cls in hyps.keys():\n",
    "    p = precision(refs[cls], hyps[cls])\n",
    "    r = recall(refs[cls], hyps[cls])\n",
    "    f = f_measure(refs[cls], hyps[cls], alpha=1)\n",
    "    \n",
    "    print(\"{:15s}: p={:.3f}; r={:.3f}; f={:.3f}; s={}\".format(cls, p, r, f, len(refs[cls])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 6. Supervised Learning for WSD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 6.1. Features for WSD\n",
    "- Bag-of-Words (already covered)\n",
    "- Collocational features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 6.1.1. Bag-of-Words (BOW) Classification (recap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "data = [\" \".join([t[0] for t in inst.context]) for inst in senseval.instances('interest.pos')]\n",
    "lbls = [inst.senses[0] for inst in senseval.instances('interest.pos')]\n",
    "\n",
    "print(data[0])\n",
    "print(lbls[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = MultinomialNB()\n",
    "lblencoder = LabelEncoder()\n",
    "\n",
    "stratified_split = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "\n",
    "vectors = vectorizer.fit_transform(data)\n",
    "\n",
    "# encoding labels for multi-calss\n",
    "lblencoder.fit(lbls)\n",
    "labels = lblencoder.transform(lbls)\n",
    "\n",
    "scores = cross_validate(classifier, vectors, labels, cv=stratified_split, scoring=['f1_micro'])\n",
    "\n",
    "print(sum(scores['test_f1_micro'])/len(scores['test_f1_micro']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 6.1.2. Collocational Features\n",
    "- Assume +/-n words window from target\n",
    "\n",
    "e.g. n=2\n",
    "\n",
    "`... managers expect further [declines in] [interest] [rates .]`\n",
    "\n",
    "- $w_{-1}$ : `declines`\n",
    "- $w_{-2}$ : `in`\n",
    "- $w_0$ __target__ : `interest`\n",
    "- $w_{+1}$ : `rates`\n",
    "- $w_{+2}$ : `.`\n",
    "\n",
    "- POS-tags of these words\n",
    "- word ngrams in window +/-3 are common\n",
    "    - ngram(-3): declines in interest\n",
    "    - ngram(-2): in interest\n",
    "    - ngram(1): interest\n",
    "    - ngram(2): interest rates\n",
    "    - ngram(3): interest rates .\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "##### Using Collocational Features in scikit-learn\n",
    "- represent features as dict\n",
    "- use `DictVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def collocational_features(inst):\n",
    "    p = inst.position\n",
    "    return {\n",
    "        \"w-2_word\": 'NULL' if p < 2 else inst.context[p-2][0],\n",
    "        \"w-1_word\": 'NULL' if p < 1 else inst.context[p-1][0],\n",
    "        \"w+1_word\": 'NULL' if len(inst.context) - 1 < p+1 else inst.context[p+1][0],\n",
    "        \"w+2_word\": 'NULL' if len(inst.context) - 1 < p+2 else inst.context[p+2][0]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data_col = [collocational_features(inst) for inst in senseval.instances('interest.pos')]\n",
    "print(data_col[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "dvectorizer = DictVectorizer(sparse=False)\n",
    "dvectors = dvectorizer.fit_transform(data_col)\n",
    "\n",
    "scores = cross_validate(classifier, dvectors, labels, cv=stratified_split, scoring=['f1_micro'])\n",
    "\n",
    "print(sum(scores['test_f1_micro'])/len(scores['test_f1_micro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### 6.1.3. Concatenating Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# let's check shape's for sanity & types (for illustration)\n",
    "print(vectors.shape, type(vectors))\n",
    "print(dvectors.shape, type(dvectors))\n",
    "\n",
    "# types of CountVectorizer and DictVectorizer outputs are different \n",
    "# we need to convert them to the same format\n",
    "uvectors = np.concatenate((vectors.toarray(), dvectors), axis=1)\n",
    "\n",
    "print(uvectors.shape, type(uvectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# cross-validating classifier the usual way\n",
    "scores = cross_validate(classifier, uvectors, labels, cv=stratified_split, scoring=['f1_micro'])\n",
    "\n",
    "print(sum(scores['test_f1_micro'])/len(scores['test_f1_micro']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Lab Exercise\n",
    "**Same test set for all the experiments, you can use K-fold validation**\n",
    "\n",
    "- Extend collocational features with\n",
    "    - POS-tags\n",
    "    - Ngrams within window\n",
    "- Concatenate BOW and new collocational feature vectors & evaluate\n",
    "- Evaluate Lesk Original and Graph-based (Lesk Similarity or Pedersen) metrics on the same test split and compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
